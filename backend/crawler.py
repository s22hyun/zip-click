import time
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from selenium.common.exceptions import TimeoutException

def setup_driver():
    options = uc.ChromeOptions()
    options.binary_location = "/usr/bin/chromium"
    options.add_argument('--headless=new')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument("window-size=1920x1080")
    driver = uc.Chrome(
        options=options,
        driver_executable_path="/usr/bin/chromedriver"
    )
    return driver

def scrape_site(driver, site_info):
    target_url = site_info["target_url"]
    site_name = site_info["name"]
    selector = site_info["selector"]

    print(f"\nâœ… {site_name} í¬ë¡¤ë§ ì‹œìž‘...")
    
    try:
        print(f"   - ëª©í‘œ íŽ˜ì´ì§€ë¡œ ì´ë™: {target_url}")
        driver.get(target_url)

        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))
        elements = driver.find_elements(By.CSS_SELECTOR, selector)
        
        print(f"\n--- {site_name} ê³µê³  ({len(elements)}ê°œ) ---")
        for el in elements:
            title = el.text
            link = el.get_attribute('href')
            if title.strip():
                print(f"   - ì œëª©: {title.strip()}")
                print(f"     ë§í¬: {link}")
        
        print("--------------------")

    except TimeoutException:
        print(f"   - ðŸš¨ ì˜¤ë¥˜: '{selector}' ìš”ì†Œë¥¼ ì°¾ëŠ” ë° ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
        screenshot_path = f"{site_name}_error.png"
        html_path = f"{site_name}_error.html"
        driver.save_screenshot(screenshot_path)
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(driver.page_source)
        print(f"   - ë””ë²„ê¹… íŒŒì¼ ì €ìž¥ ì™„ë£Œ: {screenshot_path}, {html_path}")
    except Exception as e:
        print(f"   - ðŸš¨ ì˜¤ë¥˜: {site_name} í¬ë¡¤ë§ ì¤‘ ì˜ˆì¸¡í•˜ì§€ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    finally:
        print(f"ðŸ {site_name} í¬ë¡¤ë§ ì™„ë£Œ.")


if __name__ == "__main__":
    lh_info = {
        "name": "LH ì²­ì•½í”ŒëŸ¬ìŠ¤",
        "target_url": "https://apply.lh.or.kr/lhapply/apply/wt/wrtanc/selectWrtancList.do?mi=1026",
        "selector": "td.bbs_tit > a"
    }
    
    sh_info = {
        "name": "SH ì¸í„°ë„·ì²­ì•½ì‹œìŠ¤í…œ",
        "target_url": "https://www.i-sh.co.kr/main/lay2/program/S1T294C295/www/brd/m_241/list.do",
        "selector": "#listTb td.txtL > a"
    }

    driver = setup_driver()
    try:
        scrape_site(driver, lh_info)
        scrape_site(driver, sh_info)
    finally:
        driver.quit()